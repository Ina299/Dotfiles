Info file: wget-ja.info,    -*-Text-*-
produced by `texinfo-format-buffer'
from file `wget-ja.texi'
using `texinfmt.el' version 2.38 of 3 July 1998.





INFO-DIR-SECTION Net Utilities
INFO-DIR-SECTION World Wide Web
START-INFO-DIR-ENTRY
* Wget(ja): (wget-ja).         The non-interactive network downloader.
END-INFO-DIR-ENTRY


This file documents the the GNU Wget utility for downloading network
data.

Copyright (C) 1996, 1997, 1998, 2000, 2001 Free Software Foundation,
Inc.

Permission is granted to make and distribute verbatim copies of this
manual provided the copyright notice and this permission notice are
preserved on all copies.

Permission is granted to copy, distribute and/or modify this document
under the terms of the GNU Free Documentation License, Version 1.1 or
any later version published by the Free Software Foundation; with the
Invariant Sections being "GNU General Public License" and "GNU Free
Documentation License", with no Front-Cover Texts, and with no
Back-Cover Texts.  A copy of the license is included in the section
entitled "GNU Free Documentation License".




File: wget-ja.info, Node: Top, Next: Overview, Prev: (dir), Up: (dir)

Wget  1.8.1
***********

このマニュアルは，GNU Wgetのバージョン 1.8.1を説明した文章で，それはネッ
トワークダウンロードのために自由に利用可能なユーティリティです．

Copyright (C) 1996, 1997, 1998, 2000, 2001 Free Software Foundation,
Inc.

* Menu:

* Overview::            Features of Wget.
* Invoking::            Wget command-line arguments.
* Recursive Retrieval:: Description of recursive retrieval.
* Following Links::     The available methods of chasing links.
* Time-Stamping::       Mirroring according to time-stamps.
* Startup File::        Wget's initialization file.
* Examples::            Examples of usage.
* Various::             The stuff that doesn't fit anywhere else.
* Appendices::          Some useful references.
* Copying::             You may give out copies of Wget and of this manual.
* Concept Index::       Topics covered by this manual.



File: wget-ja.info, Node: Overview, Next: Invoking, Prev: Top, Up: Top

概要
****

GNU Wgetは，Webから対話的ではないファイルのダウンロードを行なうためのフ
リーのユーティリティです．HTTP，HTTPS，そしてFTPをサポートしていて，HTTP
プロキシからの回収も同様にサポートしています．

この章は，Wgetの機能の部分的な概要となっています．

   * Wgetは対話的ではなく，つまりそれはユーザがログオンしていない間にバッ
     クグラウンドで動作可能なことを意味しています．このため，Wgetが仕事
     終らせながら，回収を開始しシステムとの接続を終了する(システムと離れ
     ている)ことが可能になっています．それと比較して，ほとんどのウェブブ
     ラウザは常にユーザの存在を要求し，それは大量のデータを転送している
     とき大きな障害となります．


   * Wgetは，HTMLページのリンクをたどり，遠隔地のウェブサイトのローカル
     バージョンを作成し，それはオリジナルサイトのディレクトリ構造を完全
     に再生成します．これは"再帰的なダウンロード"と言われることもありま
     す．こうしている間，WgetはRobot Exclusion Standard (`/robots.txt')
     を考慮します．オフラインで閲覧するために，ダウンロードされたHTMLファ
     イルのリンクをローカルのファイルに変換するよう，Wgetに指示すること
     が可能です．


   * ファイル名のワイルドカードへの一致と，ディレクトリの再帰的なミラー
     は，FTPで回収するときに利用可能です．Wgetは，HTTPサーバとFTP サーバ
     の両方でタイムスタンプ情報を読み込み，それをローカルに保存すること
     が可能です．それにより，Wgetはリモートファイルの前回の回収から変化
     しているかどうかを理解し，変化がある場合，新しいバージョンを自動的
     に回収することが可能になっています．これで，Wgetがホームページと同
     様にFTPサイトのミラーに適するようになっています．


   * Wgetは，遅く不安定なネットワークの接続越しでも耐性があるように設計
     されました．ネットワークの問題でダウンロードに失敗した場合，ファイ
     ル全体が回収されるまでリトライを続けます．サーバがリゲットをサポー
     トしている場合，残っている場所からダウンロードを続けるようサーバに
     伝えます．


   * Wgetはプロキシサーバをサポートし，それはネットワークの負荷を軽くし，
     回収の速度を上げ，そしてファイアーウォールの裏からのアクセスを提供
     することを可能にします．しかし，socks形式のゲートウェイの使用が必要
     なファイアーウォールの裏にいる場合，socksライブラリを入手しsocksサ
     ポートを用いてWgetをビルドすることが可能です．Wgetは，受動的なFTPダ
     ウンロードもオプションとしてサポートしています．


   * 組込みの機能は，希望するリンクをたどることを調整するメカニズムを提
     供します(*Note Following Links::) ．


   * 回収は通常，ドットを出力しながら追跡し，それぞれのドットは受信した
     データの固定量(デフォルトで1KB)を表現しています．これらの表現は好み
     によりカスタマイズ可能です．


   * ほとんどの機能は完全に構成変更することができ，それらは，コマンドラ
     インオプションや初期化ファイル`.wgetrc' (*Note Startup File::)を通
     じて行います．Wgetでは，サイト設定に対して"グローバルな"スタートアッ
     プファイル(デフォルトで`/usr/local/etc/wgetrc')で定義可能になってい
     ます．



   * 最後になりますが，GNU Wgetはフリーソフトウェアです．このことは，
     Free Software Foundationが出版しているGNU一般公有使用許諾書(*Note
     Copying::) の用語の下で，誰でも使用し，再配布し，そして/または修正
     が可能だということを意味します．



File: wget-ja.info, Node: Invoking, Next: Recursive Retrieval, Prev: Overview, Up: Top

呼び出し
********

デフォルトで，Wgetは呼び出し非常に簡単です．基本的な構文は以下の通りです．

     wget [OPTION]... [URL]...

Wgetは，コマンドラインで指定された全てのURLを，単純にダウンロードします．
URLは，以下で定義されるような"Uniform Resource Locator" です．

しかし，Wgetのデフォルトパラメータをいくつか変更したいかもしれません．そ
うするためには2つの利用可能な方法があります．永久的に適切なコマンドを
`.wgetrc' (*Note Startup File::)に追加する方法と，コマンドラインで指定す
る方法です．

* Menu:

* URL Format::
* Option Syntax::
* Basic Startup Options::
* Logging and Input File Options::
* Download Options::
* Directory Options::
* HTTP Options::
* FTP Options::
* Recursive Retrieval Options::
* Recursive Accept/Reject Options::



File: wget-ja.info, Node: URL Format, Next: Option Syntax, Prev: Invoking, Up: Invoking

URLの書式
=========

"URL"は，Uniform Resource Locatorの略語です．uniform resource locatorは
インターネットで利用可能なリソースに対するコンパクトな文字列表示です．
WgetはURL構文をRFC1738に従って理解します．これは，最も広く使用されている
形式です(角カッコはオプション部分を意味します)．

     http://host[:port]/directory/file
     ftp://host[:port]/directory/file

ユーザ名とパスワードをURL内部に符号化できます．

     ftp://user:password@host/path
     http://user:password@host/path

USERまたはPASSWORDのどちらか，または両方とも無くても構いません．HTTPユー
ザ名やパスワードのどちらか一方を省いている場合，認証は送られません．FTP 
ユーザ名を省いている場合，`anonymous'が使用されます．FTPパスワードを省い
ている場合，電子メールのアドレスがデフォルトパスワードとして提供されます． 
(1) (*Note URL Format-Footnotes::)

URLでの安全ではない符号化は`%xy'で可能で，`xy'は文字のASCII値の16進の表
現です．一般的な安全でない文字は，`%' (`%25'として引用されます)，`:'
(`%3A'として引用されます)，そして`@' (`%40'として引用されます)が含まれま
す．安全でない文字の包括的なリストは，RFC1738を参照してください．

Wgetは，FTP URLの`type'の機能もサポートします．デフォルトで，FTPドキュメ
ントはバイナリモードで回収(type `i')し，それはダウンロードで変更されない
ことを意味します．その他の役に立つモードは`a' ("ASCII")モードで，それは
異なるオペレーティングシステムの間で行の分離文字を変換し，そのためそれは
テキストファイルで役に立ちます．例は以下のようになります．

     ftp://host/directory/file;type=a

歴史的(ヒステリック?)な理由と広範囲で使用されていることから，URL指定の代
替となる変種もサポートされています．

FTP-only syntax (`NcFTP'でサポートされました):
     host:/dir/file

HTTP-only syntax (`Netscape'で導入されました):
     host[:port]/dir/file

これら2つの代替形式は推奨されず，将来のサポートはやめるかもしれません．

これらの表記の違いを理解できなかったり，その使い方を知らない場合，`Lynx'
や`Netscape'のような好みのブラウザで使用するプレーンな普通の書式を使用し
てください．



File: wget-ja.info  Node: URL Format-Footnotes, Up: URL Format

(1) ホームディレクトリに`.netrc'ファイルがある場合，パスワードはそ
こで検索されます．



File: wget-ja.info, Node: Option Syntax, Next: Basic Startup Options, Prev: URL Format, Up: Invoking

オプションの構文
================

Wgetは，引数の処理にGNU getoptsを使用しているので，全てのオプションには
短い形式と長い形式があります．長いオプションは覚え易くより便利なのですが，
入力に時間がかかります．異なるオプションスタイルを自由に混ぜて使用したり，
コマンドライン引数の後にオプションを指定したりしてもかまいません．このた
め，以下のように書くことができます．

     wget -r --tries=10 http://fly.srk.fer.hr/ -o log

オプションを受け入れる引数とその引数の間のスペースは省略できます．`-o
log'の代わりに`-olog'と書くことができます．

引数が不要な複数のオプションを，以下のようにまとめて書き込むことができま
す．

     wget -drc URL

これは，以下と完全に等価です．

     wget -d -r -c URL

オプションは引数の後に指定できるので，それらは`--'で終端することができま
す．そのため，以下ではURL `-x'をダウンロードしようとし，`log'に失敗を報
告します．

     wget -o log -- -x

カンマで分離されているリストを受け入れるすべてのオプションは，空のリスト
の指定がその値をクリアするという規則に従います．これは，`.wgetrc'の設定
をクリアにするとき役に立つはずです．例えば，`.wgetrc'が
`exclude_directories'を`/cgi-bin'に設定する場合，以下の例では最初にリセッ
トし，除外するものとして`/~nobody'と`/~somebody'を設定します．`.wgetrc'
(*Note Wgetrc Syntax::)のリストをクリアにすることも可能です．

     wget -X " -X /~nobody,/~somebody




File: wget-ja.info, Node: Basic Startup Options, Next: Logging and Input File Options, Prev: Option Syntax, Up: Invoking

基本的なスタートアップオプション
================================

`-V'
`--version'
     Wgetのバージョンを表示します．

`-h'
`--help'
     Wgetのすべてのコマンドラインオプションを記述するヘルプメッセージを
     出力します．

`-b'
`--background'
     開始直後にバックグラウンドに移行します．出力ファイルを`-o'で指定し
     ていない場合，出力は`wget-log'にリダイレクトされます．

`-e COMMAND'
`--execute COMMAND'
     `.wgetrc' (*Note Startup File::)の一部のように，COMMANDを実行します．
     このようなコマンドは`.wgetrc'のコマンドの*後に*実行されるので，それ
     らに優先します．



File: wget-ja.info, Node: Logging and Input File Options, Next: Download Options, Prev: Basic Startup Options, Up: Invoking

ログと入力ファイルオプション
============================

`-o LOGFILE'
`--output-file=LOGFILE'
     全てのメッセージをLOGFILEにログを取ります．メッセージは通常，標準エ
     ラー出力に報告されます．

`-a LOGFILE'
`--append-output=LOGFILE'
     LOGFILEに追加します．古いログファイルを上書きする代わりにLOGFILEに
     追加する以外，これは`-o'と同じです．LOGFILEが無い場合は，新しいファ
     イルを作成します．

`-d'
`--debug'
     デバッグ出力を開始し，それは，Wgetが正確に動作しない場合，Wgetの開
     発に様々な重要な情報として意味があります．システム管理者が，デバッ
     グサポート無しでWgetのコンパイルを選択している可能性もあり，その場
     合`-d'は動作しません．デバッグサポートでのコンパイルは常に安全だと
     いうことに注意してください--デバッグサポートでコンパイルされたWget
     は，`-d'が要求されるまでデバッグ情報を決して出力*しません*．バグレ
     ポートを送るために`-d'を使用する方法の詳細は，*Note Reporting
     Bugs::.

`-q'
`--quiet'
     Wgetの出力を停止します．

`-v'
`--verbose'
     利用可能な全てのデータを用いた冗長な出力を開始します．デフォルトの
     出力は冗長です．

`-nv'
`--non-verbose'
     冗長でない出力です--完全に静かにするのではなく(そうするには`-q'を使
     用してください)冗長を停止するということで，それはエラーメッセージと
     基本的な情報はまだ出力されることを意味します．

`-i FILE'
`--input-file=FILE'
     FILEからURLを読み込み，その場合はURLをコマンドラインに書く必要はあ
     りません．コマンド行と入力ファイルの両方にURLがある場合，コマンド行
     のものが最初に回収されます．FILEはHTMLドキュメントにする必要はあり
     ません(しかし，害が無い場合です)---URLだけ順番にリストアップされて
     いる場合はそれで十分です．

     しかし，`--force-html'を指定した場合，ドキュメントは`html'と見なさ
     れます．この状況では相対的なリンクに問題がある可能性もあり，それは，
     `<base href="URL">'をドキュメントに加えたり，コマンドラインで
     `--base=URL'を指定することで解決できます．

`-F'
`--force-html'
     ファイルから入力を読み込むとき，HTMLファイルとして扱うことを強制し
     ます．これで，ローカルディスクの既存のHTMLファイルからの相対的なリ
     ンクを，HTMLに`<base href="URL">'を加えたり，`--base'コマンドライン
     オプションを使用することで回収できるようになります．

`-B URL'
`--base=URL'
     `-F'と結合して使用されるとき，`-i'で指定されるファイル内の相対リン
     クにURLを前置します．



File: wget-ja.info, Node: Download Options, Next: Directory Options, Prev: Logging and Input File Options, Up: Invoking

ダウンロードオプション
======================

`--bind-address=ADDRESS'
     クライアントのTCP/IP接続を作成するとき，ローカルマシンのADDRESSに
     `bind()'します．ADDRESSはホスト名またはIPアドレスとして使用可能です．
     このオプションはマシンが複数のIPに連結されている場合，役に立つはず
     です．

`-t NUMBER'
`--tries=NUMBER'
     リトライの回数をNUMBERに設定します．無限のリトライのため，0や`inf'
     を指定してください．

`-O FILE'
`--output-document=FILE'
     ドキュメントは適切なファイルに書かれませんが，全て一緒に連結されて
     FILEに書き込まれます．FILEが既にある場合は上書きされます．FILEが`-'
     の場合はドキュメントは標準出力に書き込まれます．このオプションを含
     めると，リトライ回数を1に自動的に設定します．

`-nc'
`--no-clobber'
     同じディレクトリに1回以上ファイルがダウンロードされる場合，Wgetの動
     作は，`-nc'を含むいくつかのオプションに依存します．繰り返しのダウン
     ロードで，ローカルファイルは"破壊され"ることもあれば，上書きされる
     こともあります．それ以外ではそのまま残ります．

     `-N'，`-nc'，または`-r'を用いずにWgetを実行するとき，同じディレクト
     リにダウンロードされる同じファイルは，オリジナルがそのままFILEのコ
     ピーとなり，2番目のコピーは`FILE.1'と命名されます．ファイルが再びダ
     ウンロードされた場合は，3番目のコピーは`FILE.2'となり，以下同様にな
     ります．`-nc'が指定された場合はこの動作が抑制され，Wgetはより新しい
     `FILE'のコピーのダウンロードを拒否します．このため，"`no-clobber'"
     は実際にこのモードの間違った名称です---(数字の接尾子で既に破壊を妨
     げているので)それは破壊を妨げるのではなく，むしろ保存の複数のバージョ
     ンを持たないということです．

     `-r'を用い，`-N'や`-nc'を用いずにWgetを実行したとき，ファイルの再度
     のダウンロードは，古いものを単純に新しいコピーで上書きします．`-nc'
     を加えた場合はこの動作は妨げられ，オリジナルのバージョン保存し，サー
     バ上のあらゆるより新しいコピーを無視します．

     `-N'を用い，`-r'を用いるまたは用いないことで，Wgetを実行するとき，
     ローカルとリモートのファイルのタイムスタンプとサイズに依存して，よ
     り新しいファイルのダウンロードを実行するかどうかを決定します(*Note
     Time-Stamping::)．`-nc'は`-N'と同時に指定できません．

     `-nc'が指定された場合，`.html'または(反吐がでる)`.htm'の接尾子を持
     つファイルは，Webから回収されているかのようにローカルディスクからロー
     ドされて解析されることに注意して下さい．

`-c'
`--continue'
     部分的にダウンロードされたファイルの取得を続けます．これは，前回の
     Wgetのインスタンスや，他のプログラムで開始したダウンロードを完了し
     たいとき便利です．例えば以下のようにします．

          wget -c ftp://sunsite.doc.ic.ac.uk/ls-lR.Z

     現在のディレクトリに`ls-lR.Z'という名前のファイルがある場合，Wgetは，
     それがリモートファイルの最初の位置だと考え，ローカルファイルと同じ
     長さのオフセットから回収を続けるようサーバに依頼しみます．

     接続が中断されたファイルのダウンロードをリトライするために，現在の
     Wget呼び出しを行いたいだけの場合は，このオプションを指定する必要が
     ないことに注意してください．これはデフォルトの動作です．`-c'は，
     Wgetの今回の呼び出しの*前に*開始したダウンロードの再開で，そのロー
     カルファイルがまだ完全ではないものにのみに効果があります．

     `-c'を用いない場合，前の例はリモートファイルを`ls-lR.Z.1'にダウンロー
     ドし，途中で切られた`ls-lR.Z'ファイルはそのまま残ります．

     `-c'を空でないファイルで使用してWget 1.7を用いて開始すると，サーバ
     が継続ダウンロードをサポートしていないことが判明した場合は，Wgetは
     最初からのダウンロードの開始を拒否するので，その影響で既存の内容が
     だめになります．本当に最初からダウンロードを開始したい場合は，ファ
     イルを削除してください．

     また，Wget 1.7を用いて開始すると，`-c'をサーバのファイルと同じ大き
     さでないファイルで使用する場合，Wgetはファイルのダウンロードを拒否
     し，そのことを説明メッセージを出力します．サーバのファイルがローカ
     ルのものより小さいときも同じことが生じます---"続けること"に意味がな
     く，ダウンロードを行わないためです．

     反対に，`-c'を使用しているときは，ローカルより大きいサーバのファイ
     ルは不完全なダウンロードとみなされ，`((リモートの)長さ - (ローカル
     の)長さ)'バイトのみダウンロードされ，ローカルファイルの終りにくっつ
     けられます．この動作は場合によっては望ましくないものです--例えば，
     データコレクションやログファイルに追加された新しい部分をダウンロー
     ドするために，`wget -c' を使用することが可能です．

     しかし，ファイルが，*追加されて*いるのではなく，*変更されて*いてサー
     バのものより大きい場合，おかしなファイルになります．Wgetには，ロー
     カルのファイルがリモートファイルの前段が本当に有効だということを検
     証する方法がありません．`-r'と組合せて`-c'を使用するとき，すべての
     ファイルが"不完全なダウンロード"の候補と考慮されるので，このことに
     特に注意する必要があります．

     `-c'を使用してみた場合におかしなファイルを得るもう一つの例は，ロー
     カルファイルに"transfer interrupted"文字列を挿入する，不完全なHTTP
     プロキシを使用している場合です．将来は，"rollback"オプションがこの
     状況を扱うために追加されるかもしれません．

     `-c'は，FTPサーバと`Range'ヘッダをサポートするHTTPサーバのみで動作
     することに注意してください．

`--progress=TYPE'
     使用したい進行状況表示の形式を選択します．正当な表示は"ドット"と"バー
     " です．

     "ドット"の表示がデフォルトで使用されます．それは，画面上にドットを
     出力することで回収を追跡し，それぞれのドットはダウンロードされたデー
     タの固定量を表現しています．

     ドットでの回収を使用している時，`dot:STYLE'のような形式で"スタイル"
     を指定することもできます．異なるスタイルは一つのドットに異なる意味
     を割り当てます．`default'スタイルでは，それぞれのドットは1K を表現
     し，1クラスタに10ドットがあり，一行に50ドットあります．`binary'スタ
     イルでは，より"コンピュータ"ライクの方針になっています--ドットは8K，
     クラスタは16ドット，そして一行は48ドットになります(一行が384Kです)．
     `mega'スタイルは非常に大きなファイルのダウンロードに適しています--
     それぞれのドットは64Kの回収を表現していて，1クラスタに8ドットあり，
     それぞれの行には48ドットになります(そのため，それぞれの行は3M含まれ
     ています)．

     `--progress=bar'を指定することで，回収を表示している素敵なASCIIプロ
     グレスバー(a.k.a "温度計"表示)が画像として描かれます．出力がTTY出な
     い場合，このオプションは無視され，Wgetはドット表示に戻ります．バー
     の表示を強制したい場合は`--progress=bar:force'を使用してください．

`-N'
`--timestamping'
     タイムスタンプを開始します．詳細は，*Note Time-Stamping::.

`-S'
`--server-response'
     HTTPサーバが送るヘッダを出力したり，FTPサーバに返事を送ったりします．

`--spider'
     このオプションで呼び出された場合，Wgetはウェブ"スパイダー"として動
     作し，それにはページをダウンロードせずに存在を調査するという意味が
     あります．例えば，以下のようにブックマークの調査に使用可能です．

          wget --spider --force-html -i bookmarks.html

     この機能には，Wgetを真のWWWスパイダーの能力に近づけるため，非常に多
     くの仕事がさらに必要です．

`-T seconds'
`--timeout=SECONDS'
     読み込みタイムアウトをSECONDS秒に設定します．ネットワーク読み込みが
     発生するときはいつでも，ファイルディスクリプタはタイムアウトを調査
     され，それ以外では接続をペンディングのままにします(読み込みを中断し
     ません)．デフォルトタイムアウトは900秒(15分)です．タイムアウトを0に
     設定するとタイムアウトの調査が利用不可能になります．

     何を行っているか分からない場合，このオプションでタイムアウトのデフォ
     ルト値を小さくしないでください．

`-w SECONDS'
`--wait=SECONDS'
     回収の間に指定した秒数待ちます．要求の生成を少なくすることでサーバ
     の負荷を軽くするので，このオプションの使用を推奨します．秒の代わり
     に時間を`m'で後置した分，`h'を後置した時間，`d'を後置した1日で指定
     可能です．

     このオプションに大きな値を指定すると，ネットワークや接続先のホスト
     が落ちた場合，Wgetはリトライする前にネットワークエラーの修復が期待
     される程度の妥当な時間待つことができるので役に立ちます．

`--waitretry=SECONDS'
     *すべての*回収の間ではなく，ダウンロードに失敗したときのみWgetを待
     たせたい場合，このオプションを使用することが可能です．Wgetは"linear
     backoff"を使用していて，与えられたファイルでの最初の失敗の後に1秒待
     ち，そのファイルで2番目に失敗した後に2秒待つようにして，指定された
     最大SECONDSまで増加するようになっています．このため，10の値は，(1 +
     2 + ... + 10) = 55 秒まで，Wgetは1つのファイルにつき実際に待つこと
     になります．

     このオプションは，大域的な`wgetrc'ファイルでデフォルトで開始してい
     ることに注意してください．

`--random-wait'
     ウェブサイトによっては，Wgetのような回収プログラムを識別するために，
     要求と要求の間の時間で統計的に重要な類似を探すため，ログ解析を実行
     する可能性があります．このオプションは，`-w'や`--wait'オプションを
     使用して指定したWAITを用いて，0から2の間にWAIT秒を掛けて変化させ，
     要求と要求の間の時間を変動させ，そのような解析からWgetの存在を隠す
     ようになっています．

     有名なコンシュマープラットフォームでの開発に捧げられている出版物の
     最近の論文では，大至急これを解析するコードを提供しています．その著
     者は，自動的な回収プログラムでDHCPで提供するアドレスを悪意を持って
     変更するものをブロックすることを確実にするため，クラスCのアドレスレ
     ベルをブロックすることを提案しています．

     `--random-wait'オプションは，その動作を行なうウェブサイトから多くの
     無関係なユーザをブロックするような無差別な推奨があることを示唆して
     います．

`-Y on/off'
`--proxy=on/off'
     プロキシサポートを開始または停止します．適切な環境変数が定義されて
     いる場合，プロキシはデフォルトです．

`-Q QUOTA'
`--quota=QUOTA'
     自動回収に対するダウンロードクォータを指定します．値は(デフォルトで)
     バイト，(`k'の後置で)キロバイト，(`m'の後置で)メガバイトで指定可能
     です．

     クォータは単一ファイルのダウンロードで効果が無いことに注意してくだ
     さい．そのため，`wget -Q10k ftp://wuarchive.wustl.edu/ls-lR.gz'のよ
     うに指定した場合，`ls-lR.gz'全体がダウンロードされます．複数のURLが
     コマンドラインで指定されたときも，同様なことが生じます．しかし，回
     収が再帰的なときや入力ファイルからのときにクォータは尊重されます．
     このため，安全に`wget -Q2m -i sites'と入力ことができます--ダウンロー
     ドはクォータ以上になったとき中止します．

     クォータを0や`inf'に設定すると，ダウンロードクォータは無制限になり
     ます．



File: wget-ja.info, Node: Directory Options, Next: HTTP Options, Prev: Download Options, Up: Invoking

ディレクトリオプション
======================

`-nd'
`--no-directories'
     再帰的に回収するときにディレクトリの階層を作成しません．このオプショ
     ンを開始すると，全てのファイルは現在のディレクトリに上書き無しで保
     存されます(名前が1度以上現れる場合，ファイル名は拡張子`.n'が付きま
     す)．

`-x'
`--force-directories'
     `-nd'の反対です--階層無しで作成されていても，ディレクトリ階層を作成
     します．例えば，`wget -x http://fly.srk.fer.hr/robots.txt'はファイ
     ルを`fly.srk.fer.hr/robots.txt'にダウンロードします．

`-nH'
`--no-host-directories'
     ホストを前置したディレクトリの生成を不可にします．デフォルトで，
     Wgetを`-r http://fly.srk.fer.hr/'を用いて呼び出した場合，
     `fly.srk.fer.hr/'で始まるディレクトリ構造を作成します．このオプショ
     ンはそのような動作を不可にします．

`--cut-dirs=NUMBER'
     ディレクトリコンポーネントのNUMBERを無視します．再帰的回収で保存さ
     れたディレクトリ上の，きめ細かい制御でこれは役に立ちます．

     例えば，`ftp://ftp.xemacs.org/pub/xemacs/'ディレクトリの取得すると
     します．`-r'で回収した場合，`ftp.xemacs.org/pub/xemacs/'以下にロー
     カル保存されます．一方，`-nH'オプションは`ftp.xemacs.org/' の部分を
     削除し，`pub/xemacs'で保存します．これが`--cut-dirs'が役に立つとこ
     ろです．それで，WgetはリモートディレクトリコンポーネントのNUMBER(数)
     を"見"ないようなります．`--cut-dirs'オプションがどのように動作する
     かを示す例は以下のようになります．

          No options        -> ftp.xemacs.org/pub/xemacs/
          -nH               -> pub/xemacs/
          -nH --cut-dirs=1  -> xemacs/
          -nH --cut-dirs=2  -> .

          --cut-dirs=1      -> ftp.xemacs.org/xemacs/
          ...

     ディレクトリ構造を取り除きたいだけの場合，このオプションは`-nd'と
     `-P'の組合せに似ています．しかし，`-nd'とは異なり，
     `--cut-dirs'はサブディレクトリを失いません--例えば，`-nH
     --cut-dirs=1'を用いた場合，`beta/'サブディレクトリは，期待通りに
     `xemacs/beta'に配置されます．

`-P PREFIX'
`--directory-prefix=PREFIX'
     ディレクトリプレフィクスをPREFIXに設定します．"ディレクトリプレフィ
     クス"は，他の全てのファイルとサブディレクトリが保存されるディレクト
     リで，すなわち回収ツリーのトップになります．デフォルトは`.'(カレン
     トディレクトリ)です．



File: wget-ja.info, Node: HTTP Options, Next: FTP Options, Prev: Directory Options, Up: Invoking

HTTPオプション
==============

`-E'
`--html-extension'
     形式`text/html'のファイルがダウンロードされ，URLが正規表現の
     `\.[Hh][Tt][Mm][Ll]?'で終わらない場合，このオプションは接尾子
     `.html'をローカルのファイル名に後置します．例えば，`.asp'ページを使
     用したリモートサイトをミラーし，手元のApachサーバで閲覧可能なミラー
     にしたい場合，これは役に立ちます．もう一つのこの優れた利用方法は，
     CGIの出力をダウンロードするときです．
     `http://site.com/article.cgi?25'のようなURLは，
     `article.cgi?25.html'として保存されます．

     この方法で変更されたファイル名は，Wgetはローカルの`X.html'ファイル
     とリモートのURL `X'と一致するかどうか分からないため(それは，URLが生
     成する形式が`text/html'の出力が分からないためです．)，再びダウンロー
     ドするとき毎にサイトをミラーリングすることに注意してください．この
     再ダウンロードを避けるため，ファイルのオリジナルバージョンが
     `X.orig'として保存されるように，`-k'と`-K'を使用する必要があります
     (*Note Recursive Retrieval Options::)．

`--http-user=USER'
`--http-passwd=PASSWORD'
     HTTPサーバでのユーザ名をUSERに，そしてパスワードをPASSWORDに指定し
     ます．試みる形式によって，Wgetは`basic' (安全でない)，または
     `digest'認証手法のいずれかを用いて符号化します．

     もう1つの方法は，ユーザ名とパスワードをURL自身に書く方法です(*Note
     URL Format::)．Wgetの安全な発行についての詳細は，*Note Security
     Considerations::.

`-C on/off'
`--cache=on/off'
     オフに設定したときサーバサイドのキャッシュを不可にします．この場合
     Wget は，リモートサービスからファイルを得るため，キャッシュバージョ
     ンを返す代わりにリモートサーバに適切なディレクティブ(`Pragma:
     no-cache')を送ります．これは，プロキシサーバの時代遅れのドキュメン
     トを回収し，クリアするときに特に役立ちます．

     キャッシュはデフォルトで可能になっています．

`--cookies=on/off'
     オフに設定するときクッキーは使用不可能です．クッキーはサーバ側の状
     態を管理するメカニズムです．サーバは`Set-Cookie'ヘッダを使用してク
     ライアントにクッキーを送り，クライアントはそれ以降の要求で同じクッ
     キーを使用して応答します．クッキーはサーバの所有者が訪問者の追跡を
     保存し，サイトがこの情報を交換することを可能にするので，それらをプ
     ライバシーの侵害と考える人もいます．デフォルトはクッキーの使用です．
     しかし，クッキーの*保存* はデフォルトではありません．

`--load-cookies FILE'
     最初のHTTPの回収の前にFILEからクッキーをロードします．FILEの書式は，
     少なくともUnixバージョンのNetscapeとMozillaで使用されているものです．

     サイトの内容にアクセスするためにログインすることを要求するサイトを
     ミラーリングする時，このオプションを通常使用します．ログインのプロ
     セスは，通常ウェブサーバがHTTPクッキーを発行し，回収し，証明書を検
     証することで動作します．クッキーは，サイトの一部にアクセスしたとき
     ブラウザが再送信し，個人識別情報を提供します．

     サイトのミラーリングで，サイトと通信する時にウェブブラウザが送るも
     のと同じクッキーをWgetに送るよう要求します．これは，
     `--load-cookies'で達成されます--単純にWgetに`cookies.txt'ファイルが
     ある場所を示し，そうすることでブラウザが同じ状況で送るものと同じクッ
     キーを送ります．異なるブラウザはテキストのクッキーファイルを異なる
     場所に保存します．

     Netscape 4.x.
          クッキーは`~/.netscape/cookies.txt'になります．

     Mozilla and Netscape 6.x.
          Mozillaのクッキーファイルも`cookies.txt'という名前で，プロファ
          イルのディレクトリの`~/.mozilla'の下のどこかにあります．フルパ
          スは`~/.mozilla/default/SOME-WEIRD-STRING/cookies.txt'のような
          場所で見つかります．

     Internet Explorer.
          ファイルメニューの，インポートとエクスポートの，エクスポートクッ
          キーを使用することで，Wgetが使用可能なクッキーファイルを生成可
          能です (1) (*Note HTTP Options-Footnotes::)．これは，Internet
          Explorer 5でテストしました．それより前のバージョンでの動作は保
          証しません．

     その他のブラウザ(Other browsers.)
          クッキーを作成したものと異なるブラウザを使用している場合，場所
          を指定可能，またはWgetが期待するNetscapeのフォーマットのクッキー
          ファイルを生成することが可能な場合のみ動作します．

     `--load-cookies'が使用不可能な場合，代替方法もあります．ブラウザが"
     クッキーマネージャ"をサポートしている場合，ミラーしているサイトにア
     クセスする時，使用されているクッキーを見るためにそれを使用すること
     が可能です．名前とクッキー名を書き下ろし，手動でこれらのクッキーを
     送るようWgetに命令し，"公式の"クッキーサポートを回避してください．

          wget --cookies=off --header "Cookie: NAME=VALUE"

`--save-cookies FILE'
     セッションの終りにFILEにクッキーを保存します．破棄する時間が指定さ
     れていないクッキーや，既に期限切れのクッキーは，保存されません．

`--ignore-length'
     残念ながら，HTTPサーバ(より正確にはCGIプログラム)には，偽の
     `Content-Length'ヘッダを送るものもあり，それではドキュメント全てが
     回収されないので，Wgetがおかしくなります．Wgetが同じドキュメントを
     何度も何度も回収し，そのたび毎に(通常でない)接続が同じバイト数で閉
     じている報告を得る場合，この症状を見付けることが可能です．

     このオプションを用いた場合，Wgetは`Content-Length'ヘッダを--まるで
     存在しないかのように--無視します．

`--header=ADDITIONAL-HEADER'
     HTTPに渡すADDITIONAL-HEADERを定義します．ヘッダは，1つ以上の空白で
     はない文字が前置されている`:'を含んでいて，それには改行を含めてはな
     りません．

     1つ以上の追加ヘッダを，1度以上`--header'を指定することで定義できま
     す．

          wget --header='Accept-Charset: iso-8859-2' \
               --header='Accept-Language: hr'        \
                 http://fly.srk.fer.hr/

     ヘッダ値として空の文字列を指定すると，以前ユーザが定義した全てのヘッ
     ダをクリアします．

`--proxy-user=USER'
`--proxy-passwd=PASSWORD'
     プロキシサーバの認証のため，ユーザ名USERとパスワードPASSWORD を指定
     します．Wgetはこれらを`basic'認証手法で符号化します．

`--referer=URL'
     HTTPの要求に`Referer: URL'ヘッダを含めます．常に対話的なウェブブラ
     ウザでの回収を期待していて，Refererがそれを示すページの一つに設定さ
     れているときのみ正しく出力するサーバサイドプロセスを用いたドキュメ
     ントの回収で役に立ちます．

`-s'
`--save-headers'
     HTTPサーバがファイルにつけて送ったヘッダを空白行で分けて，実際の内
     容の前につけて保存します．

`-U AGENT-STRING'
`--user-agent=AGENT-STRING'
     AGENT-STRINGとしてHTTPサーバを識別します．

     HTTPプロトコルは，クライアントが`User-Agent'ヘッダフィールドを用い
     た自分自身の識別を許可しています．これでWWWソフトウェアの区別が可能
     となり，通常のプロトコル違反の追跡目的には十分です．Wgetは通常
     `Wget/VERSION'として識別され，VERSIONはWgetの現在のバージョンナンバー
     です．

     しかし，サイトによっては`User-Agent'が供給する情報によって出力を調
     整するポリシーを課すことが知られています．概念的には，これはそんな
     に悪い考えではないのですが，`Mozilla'やMicrosoft `Internet
     Explorer' 以外のクライアントに情報の提供を拒否するように乱用されて
     もいました．このオプションで，Wgetが発行する`User-Agent'を変更でき
     ます．このオプションの使用は，行っていることを本当に知らない場合は
     思い留まってください．


File: wget-ja.info  Node: HTTP Options-Footnotes, Up: HTTP Options

(1) 訳注：IE は使っていないので，日本語のものはどうなっている
か分かりません．



File: wget-ja.info, Node: FTP Options, Next: Recursive Retrieval Options, Prev: HTTP Options, Up: Invoking

FTPオプション
=============

`-nr'
`--dont-remove-listing'
     FTPの回収で生成された，一時的な`.listing'を削除しません．通常，これ
     らのフィルはFTPサーバから得た生のディレクトリリストを含んでいます．
     それを削除しないことで，デバッグが目的のときや，リモートサーバのディ
     レクトリの内容について簡単な調査を可能にしたい時に役に立つはずです
     (例えば，実行しているミラーが完全なことを検証します)．

     Wgetが既知のファイル名にこのファイルを書いたとしても，ユーザが
     `.listing'のシンボリックリンクを`/etc/passwd'に作成したり，`root'に
     Wgetをそのホームディレクトリで実行するように頼むといったシナリオで
     も，これはセキュリティホールにはならないことに注意してください．使
     用するオプションに依存して，Wgetは`.listing'への書き込みを拒否した
     り，glob/再帰/タイムスタンプの処理を失敗させたり，シンボリックリン
     クが削除されたり実際の`.listing'ファイルに置換されたり，リストが
     `.listing.NUMBER'ファイルに書き込まれたりします．

     この状況に問題があっても，`root'は決してWgetを信頼できないユーザの
     ディレクトリで実行しません．ユーザは`index.html'を`/etc/passwd'にリ
     ンクしたり，ファイルが上書きされるように`root'に`-N'や`-r'を用いて
     Wgetを実行するように頼むような，簡単なことしかできません．

`-g on/off'
`--glob=on/off'
     FTP globをオン/オフします．globはシェルのような特別文字("ワイルドカー
     ド")を意味し，同じディレクトリから一度に1つ以上のファイルを回収する
     ための`*'，`?'，`['と`]'のようなもので，以下のようにします．

          wget ftp://gnjilux.srk.fer.hr/*.msg

     デフォルトで，URLがglob文字を含む場合，globはオンです．このオプショ
     ンで永久的にglobのオン/オフに使用できます．

     シェルによる展開から保護するため，URLを引用符で囲む必要があるかもし
     れません．globでWgetにディレクトリリストを探し，それはシステム指定
     のものになっています．これは，現在の仕事がFTPサーバでのみ動作するか
     らです(そしてそれは，Unix `ls'出力をエミュレートします)．

`--passive-ftp'
     "passive" FTP回収手法を使用し，そこでクライアントはデータ接続を開始
     します．これは，FTPをファイアーウォールの後ろから動作させるため，必
     要なときもあります．

`--retr-symlinks'
     通常，FTPディレクトリを再帰的にダウンロードし，シンボリックリンクに
     遭遇したとき，リンクされているファイルはダウンロードされません．そ
     の代わりに，一致したシンボリックリンクはローカルファイルシステムに
     作成されます．指し示されたファイルは，この再帰的な回収が個別に遭遇
     したとき，それを何とかしてダウンロードしようとしない限りダウンロー
     ドされません．

     しかし，`--retr-symlinks'が指定されている場合，シンボリックリンクは
     切断され，指定されたファイルが回収されます．この時，このオプション
     で，Wgetはディレクトリに対するシンボリックリンクを切断せずに，その
     まま残しますが，将来はこうなるように拡張されるでしょう．

     ファイル(ディレクトリではない)の回収時には，それが切断されているた
     めではなく，それがコマンドラインで指定されているために，このオプショ
     ンの効果がなくなります．シンボリックリンクは，この場合は常に切断さ
     れます．



File: wget-ja.info, Node: Recursive Retrieval Options, Next: Recursive Accept/Reject Options, Prev: FTP Options, Up: Invoking

再帰的な回収オプション
======================

`-r'
`--recursive'
     再帰的な回収を開始します．詳細は*Note Recursive Retrieval::.

`-l DEPTH'
`--level=DEPTH'
     再帰的な最大深度レベルをDEPTHに設定します．(*Note Recursive
     Retrieval::)．デフォルト最大深度は5です．

`--delete-after'
     このオプションは，ダウンロードした*後*に全ての単一ファイルを削除す
     るようWgetに伝えます．それはプロキシから取得した一般的なページに対
     し便利で，例えば以下のようにします．

          wget -r -nd --delete-after http://whatever.com/~popular/page/

     `-r'オプションは再帰的に回収し，`-nd'はディレクトリを作成しません．

     `--delete-after'がローカルマシンのファイルを削除することに注意して
     ください．例えばそれは，リモートのFTPサイトに`DELE'コマンドを発行し
     ません．また`--delete-after'が指定されたとき，`.orig'ファイルが単純
     に最初の位置に作成されないため，`--convert-links'が無視されることに
     も注意してください．

`-k'
`--convert-links'
     ダウンロードが完了した後，ドキュメント内のリンクをローカルでの閲覧
     に適したものに変換します．これは目に見えるハイパーリンクのみならず，
     埋め込み画像，スタイルシートへのリンク，HTMLでない内容へのハイパー
     リンク等のように，外部の内容にリンクしているドキュメントの，あらゆ
     る部分にも影響があります．

     それぞれのリンクは２つの方法のうちの一つで変換されます．

        * Wgetでダウンロードされたファイルへのリンクは，相対的なリンクと
          してそれが示すファイルへの参照を変更します．

          例：ダウンロードされたファイル`/foo/doc.html'が`/bar/img.gif'
          にリンクしていて，それもダウンロードされている場合，`doc.html'
          内のリンクは`../bar/img.gif'を示すものに変更されます．この種の
          変換は，ディレクトリの任意の結合が信頼できるように動作します．

        * Wgetがダウンロードしていないファイルへのリンクは，ホスト名とそ
          れが示す場所の絶対パスに変更されます．

          例：ダウンロードされたファイル`/foo/doc.html'が，
          `/bar/img.gif' (または`../bar/img.gif')へリンクしている場合，
          `doc.html'内のリンクは`http://HOSTNAME/bar/img.gif'を示すもの
          に変更されます．

     このため，ローカルでの閲覧が信頼できるように動作します．リンクされ
     ているファイルがダウンロードされている場合，リンクはそのローカル名
     を参照します．それがダウンロードされていない場合は，リンクは存在す
     る壊れたリンクではなく，その完全なインターネットアドレスを参照しま
     す．前のリンクが相対リンクに変換されるという事実は，ダウンロードさ
     れた階層を別のものに移動することを確実に可能にします．

     ダウンロード後のみ，Wgetはリンクがダウンロードされたことを知ること
     ができます．そのため，`-k'が行う仕事は，すべてのダウンロード終りに
     実行されます．

`-K'
`--backup-converted'
     ファイルの変換時に，オリジナルバージョンのファイルを`.orig'接尾子を
     用いてバックアップします．`-N'の動作に効果があります(*Note HTTP
     Time-Stamping Internals::)．

`-m'
`--mirror'
     ミラーに適したオプションを開始します．このオプションは回収とタイム
     スタンプを開始し，無限の再帰深度を設定し，FTPディレクトリリストを保
     ちます．現在は，`-r -N -l inf -nr'と同じです．

`-p'
`--page-requisites'
     このオプションで，Wgetは与えられたHTMLページを適切に表示するのに必
     要なすべてのファイルをダウンロードします．これは，画像，音声，そし
     て参照されるスタイルシートのようなものを含みます．

     通常は，単一のHTMLページをダウンロードするとき，正しく表示するのに
     要求される可能性のある，必要なドキュメントも全くダウンロードされま
     せん．`-l'を用いた`-r'オプションの使用は役に立つはずですが，Wgetは
     外部とインラインドキュメントを通常区別するので，通常は失われた必要
     なものとなる"leaf documents"として残ったままです．

     例えば，`1.gif'を参照する`<IMG>'タグと，外部ドキュメント`2.html'を
     指し示す`<A>'タグを含む，ドキュメントを考えます．`2.html'は似ていま
     すが，その画像`2.gif'でそのリンクは`3.html'とします．この繰り返しは，
     任意の，より大きい数字まであるとします．

     以下のコマンドを実行したとします．

          wget -r -l 2 http://SITE/1.html

     すると，`1.html'，`1.gif'，`2.html'，`2.gif'，そして`3.html'はダウ
     ンロードされます．見てお分かりのように，再帰を停止する場所を決定す
     るために，Wgetは，`1.html'からのホップの数(を2まで) しか数えないの
     で，`3.html'にはそれが必要とする`3.gif'がありません．しかし，以下の
     コマンドを用いたとします．

          wget -r -l 2 -p http://SITE/1.html

     それは，上記のすべてのファイル*および*`3.html'が必要とする`3.gif'が
     ダウンロードされます．同様に，以下のようにします．

          wget -r -l 1 -p http://SITE/1.html

     これで，`1.html'，`1.gif'，`2.html'，そして`2.gif'がダウンロードさ
     れます．このように考えることもできます．

          wget -r -l 0 -p http://SITE/1.html


     これは，`1.html'と`1.gif'のみをダウンロードすると思われますが，`-l
     0'は`-l inf'---すなわち無限再帰--と等価なので，残念ながらそうなりま
     せん．単一のHTMLページ(または，コマンドラインや`-i' URL入力ファイル
     で指定された少数のもの)とその(またはそれらの)必需品をダウンロードす
     るために，単に`-p'と`-l'のみ残してください．

          wget -p http://SITE/1.html

     Wgetは，`-r'が指定されたかのように動作しますが，単一のページとその
     必需品のみダウンロードされることに注意してください．外部ドキュメン
     トへのリンクはだとりません．実際，単一のページとその必需品を(たとえ
     別のウェブサイトに存在していても)ダウンロードするためと，ひとまとま
     りで正しくローカルに表示することを保証するために，この作者は，`-p'
     に加えていくつかのオプションを使用することを好みます．

          wget -E -H -k -K -p http://SITE/DOCUMENT

     このトピックの終りになりますが，外部ドキュメントへのリンクだとWget
     が考える方法は，`<A>'タグ，`<AREA>'タグ，または，`<LINK
     REL="stylesheet">'以外の`<LINK>'タグで指定されているあらゆるURLがそ
     うであると考えるという方法です．



File: wget-ja.info, Node: Recursive Accept/Reject Options, Prev: Recursive Retrieval Options, Up: Invoking

再帰の適応/拒絶オプション
=========================

`-A ACCLIST --accept ACCLIST'
`-R REJLIST --reject REJLIST'
     受け入れるまたは拒絶する，カンマで分けられたファイル名の接尾子やパ
     ターンを指定します(詳細は，*Note Types of Files::)．

`-D DOMAIN-LIST'
`--domains=DOMAIN-LIST'
     (リンクを)たどるドメインを設定します．DOMAIN-LISTはカンマで分けられ
     たドメインのリストです．`-H'を開始しないことに注意してください．

`--exclude-domains DOMAIN-LIST'
     (リンクを)たどら*ない*ドメインを指定します．(*Note Spanning
     Hosts::)．

`--follow-ftp'
     HTMLドキュメントからのFTPリンクをたどります．このオプションが無い場
     合，Wgetは全てのFTPリンクを無視します．

`--follow-tags=LIST'
     再帰的な回収でリンクされているドキュメントを探すとき，HTMLタグ / の
     属性の対になると考えられるの内部テーブルを持っています．しかし，ユー
     ザが考慮すべきタグのサブセットのみ欲しい場合，このオプションととも
     に，カンマで分けられているLIST内のタグを指定すべきです．

`-G LIST'
`--ignore-tags=LIST'
     これは，`--follow-tags'オプションの反対です．ダウンロードするドキュ
     メントを再帰的に探すとき，特定のHTMLタグをスキップするため，カンマ
     で分けられたLIST内で指定してください．

     以前は，`-G'オプションは，単一のページとその必要物をダウンロードす
     るとき最善の策で，それは以下のようなコマンドラインになりました．

          wget -Ga,area -H -k -K -r http://SITE/DOCUMENT

     しかし，このオプションの作者は，`<LINK REL="home" HREF="/">'のよう
     なタグを用いたページに出会い，`-G'が現実的ではないことを実感しまし
     た．スタイルシートがダウンロードされないため，Wgetに`<LINK>'を無視
     させるように伝えることができませんでした．現在は，単一のページとそ
     の必要物をダウンロードする最善の策は，`--page-requisites'オプション
     を掲げています．

`-H'
`--span-hosts'
     再帰的な回収時に，ホストに跨ることを可能とします(*Note Spanning
     Hosts::)．

`-L'
`--relative'
     相対リンクのみたどります．同じホストからでも気にしないで，特定のホー
     ムページを回収することに役立ちます(*Note Relative Links::)．

`-I LIST'
`--include-directories=LIST'
     ダウンロード時に，(リンクを)だどりたいディレクトリのカンマで分けら
     れたリストを指定します(詳細は，*Note Directory-Based Limits::)．
     LISTの要素にはワイルドカードを含めることができます．

`-X LIST'
`--exclude-directories=LIST'
     ダウンロードから削除したいディレクトリの，カンマで分けられたリスト
     を指定します(詳細は，*Note Directory-Based Limits::)．LISTの要素は
     ワイルドカードを含めることができます．

`-np'
`--no-parent'
     再帰的な回収時に親ディレクトリへ登りません．特定の階層*以下の*ファ
     イルのみダウンロードすることを保証するので，これは便利なオプション
     です．詳細は，*Note Directory-Based Limits::.




File: wget-ja.info, Node: Recursive Retrieval, Next: Following Links, Prev: Invoking, Up: Top

再帰的な回収
************

GNU Wgetは，Web(または，単一のHTTPやFTPサーバ)の部分を，リンクとディレク
トリ構造をたどりながら渡り歩くことができます．これは"再帰的な回収"，また
は"再帰"と呼ばれます．

HTTP URLを用いると，Wgetは与えられたURLすなわちドキュメントから得たHTML
を，`href'や`src'のようなマークアップを通じて，HTMLドキュメントが参照し
ているファイルを回収しながら，回収と解析を行ないます．新たにダウンロード
されたファイルも`text/html'形式の場合も，それは解析され更に続けます．

HTTPの再帰的な回収とHTMLの内容は"breadth-first"です．これは，要求された
HTMLドキュメントをWgetが最初に，その後でドキュメントがリンクしているドキュ
メントを，そして更にそれがリンクしているドキュメントというようにダウンロー
ドすることを意味します．言い替えると，Wgetは最初に深さ1のドキュメントを
ダウンロードし，それから深さ2のものというようにして最大深度で指定された
ものまでダウンロードするということです．

回収が下降する最大の"深度"は，`-l'オプションで指定されます．デフォルトの
最大深度は5階層です．

FTP URLを再帰的に回収するとき，Wgetはリモートサーバの与えられた(指定され
た深度以上のサブディレクトリを含め)ディレクトリツリーから，全てのデータ
を回収し，ローカルにミラーイメージを作成します．FTPの回収も`depth'パラメー
タで制限されます．HTTPの再帰と異なり，FTPの再帰は最初の深度で実行されま
す．

デフォルトで，Wgetはローカルディレクトリツリーを作成し，それはリモートサー
バで見つかったものに対応しています．

再帰的回収は複数の応用が可能で，最も重要なものはミラーです．それは，WWW
の公開と，その他の状況として，ネットワーク接続が遅いところでファイルをロー
カルに保存することでバイパスすることで役に立ちます．

再帰呼び出しはネットワークを通じたデータの高速転送になるため，システムの
過負荷を起こす可能性があることを警告します．このため，管理者の多くはそれ
に難色を示していて，大量の内容物を高速にダウンロードしているのを検出した
場合，あなたのサイトからのアクセスを禁止するかもしれません．Internetサー
バからダウンロードしている時，サーバへのアクセスの間の遅延を導入するため，
`-w'オプションを使用することを考慮に入れてしてください．ダウンロードには
より長い時間がかかりますが，サーバ管理者はあなたの無礼には心配無くなるで
しょう．

もちろん，再帰的なダウンロードは自分のマシンにも問題を発生するかもしれま
せん．調査無しで実行したままにする場合，ディスクが簡単にいっぱいになるは
ずです．ローカルのネットワークからのダウンロードの場合，メモリとCPUの消
費と同様に，システムの帯域幅にも注意すべきです．

ダウンロードを達成するような試みに適した基準を指定してみてください．1ペー
ジのみダウンロードしたい場合，あらゆる再帰を追加すること無く
`--page-requisites'を使用してください．1つのディレクトリ以下をダウンロー
ドしたい場合，他のディレクトリからダウンロードすることを避けるため`-np'
を使用してください．一つのディレクトリの全てのファイルをダウンロードした
い場合，再帰深度が超過しないことを確実にするため`-l 1'を使用してください．
これについての詳細は*Note Following Links::.

再帰的な回収は注意して使用すべきです．警告しなかったとは言わせません．



File: wget-ja.info, Node: Following Links, Next: Time-Stamping, Prev: Recursive Retrieval, Up: Top

リンクの追跡
************

再帰的な回収で不必要なデータの回収になることを望む人はいません．ほとんど
いつも，ダウンロードしたいものとWgetにたどらせたい特定のリンクのみを，ユー
ザは正しく覚えています．

例えば，`fly.srk.fer.hr'から音楽のアーカイブをダウンロードしたい場合，アー
カイブの曖昧な部分の参照から生じる，全てのホームページのダウンロードを望
みません．

たどりたいリンクを正確に調整することを可能とする，いくつかのメカニズムが
Wgetにはあります．

* Menu:

* Spanning Hosts::         (Un)limiting retrieval based on host name.
* Types of Files::         Getting only certain files.
* Directory-Based Limits:: Getting only certain directories.
* Relative Links::         Follow relative links only.
* FTP Links::              Following FTP links.



File: wget-ja.info, Node: Spanning Hosts, Next: Types of Files, Prev: Following Links, Up: Following Links

ホストを跨ぐ
============

Wgetの再帰的な回収は，通常はコマンドラインで指定されたものと異なるホスト
を訪れることを拒否します．これはデフォルトで妥当です．そうしない場合，全
ての回収で，Wgetがgoogleの縮小版になり得ます．

しかし，異なるホストを訪れたり，"ホストを跨ぐこと"が役に立つオプションと
なる時もあります．画像が異なるサーバから提供されているかもしれません．3
つのサーバ間の内部リンクでページ構成されているサイトのミラーリングしてい
るかもしれません．サーバが2つの等価な名前を持ち，HTMLページが両方を交替
しながら参照しているかもしれません．

あらゆるホストを跨ぐ---`-H'(Span to any host---`-H')

     `-H'オプションはホストを跨ぐことを開始し，そのため，リンクで参照さ
     れている全てのホストを訪れながら，Wgetの再帰的な回収が可能となりま
     す．再帰の制限の基準が適切な深度に指定されていない限り，これらの外
     部のホストは通常更に多くのホストにリンクされていて，Wgetはあなたが
     考えていたものより遥かに多くのデータを終りまで吸い上げ続けます．

特定のドメインに跨るように制限する---`-D'(Limit spanning to certain domains---`-D')

     `-D'オプションを用いてたどるドメインを指定でき，そのため，これらの
     ドメインに所属しているホストのみ再帰的に扱うよう制限されます．`-H' 
     と組み合わせることでのみ，明確な意味があります．典型的な例として，
     `images.server.com'からのダウンロードを許可しながら`www.server.com'
     の内容をダウンロードするなどです．

          wget -rH -Dserver.com http://www.server.com/

     カンマで分けられたリスト，例えば`-Ddomain1.com,domain2.com'で，一つ
     以上のアドレスを指定することが可能です．

特定のドメインをダウンロードから除外したままにする---`--exclude-domains'(Keep download off certain domains---`--exclude-domains')

     指定から外したいドメインがある場合，`--exclude-domains'で行うことが
     可能で，それは`-D'の引数と同じ形式を受け入れますが，リストアップさ
     れた全てのドメインを*除外*します．例えば，`sunsite.foo.edu'以外の
     `foo.edu'ドメインの，全てのホストをダウンロードしたい場合，以下のよ
     うにすることで可能です．

          wget -rH -Dfoo.edu --exclude-domains sunsite.foo.edu \
              http://www.foo.edu/




File: wget-ja.info, Node: Types of Files, Next: Directory-Based Limits, Prev: Spanning Hosts, Up: Following Links

ファイルの形式
==============

ウェブから資料をダウンロードするとき，特定のファイル形式のみを回収するよ
うに制限したいときもよくあります．例えば，GIFをダウンロードすることに興
味がある場合，ポストスクリプトのドキュメントでの負荷は嬉しいはずが無く，
逆もまたそうです．

Wgetはこの問題を扱う2つのオプションを提案します．それぞれのオプションで，
短い名前，長い名前，そして`.wgetrc'内の等価コマンドをリストアップします．

`-A ACCLIST'
`--accept ACCLIST'
`accept = ACCLIST'
     `--accept'オプションの引数は，Wgetが再帰的な回収の間にダウンロード
     するファイルの，接尾子やパターンのリストです．接尾子はファイルの終
     りの部分で，"通常の"文字列，例えば`gif'や`.jpg'から成り立ちます．パ
     ターンマッチはシェルのワイルドカードを含んでいて，例えば，`books*'
     や`zelazny*196[0-9]*'です．

     そして，`wget -A gif,jpg'を指定すると，Wgetは`gif'や`jpg' で終るファ
     イルのみ，すなわちGIFとJPEGをダウンロードします．一方，`wget -A
     "zelazny*196[0-9]*"'は，`zelazny'で始まり，その中に1960から1969まで
     の数字を含むファイルのみをダウンロードします．パターンマッチの動作
     方法についての記述はシェルのマニュアルを探してください．

     もちろん，任意の数の接尾子とパターンをカンマで分けたリストで組み合
     わせることや，`-A'の引数として与えることが可能です．

`-R REJLIST'
`--reject REJLIST'
`reject = REJLIST'
     `--reject'オプションは`--accept'と同じように動作しますが，その論理
     は否定です．Wgetは，リストの接尾子(やパターン)に一致するもの*以外の
     *，全てのファイルをダウンロードします．

     そして，扱いにくいMPEGと.AUファイル以外の，ページ全体をダウン
     ロードしたい場合，`wget -R mpg,mpeg,au'を使用できます．同様に，
     `bjork'で始まるファイル以外全てをダウンロードするため，`wget
     -R "bjork*"'を使用してください．引用符はシェルによる展開を妨げるためです．

`-A'と`-R'オプションは，回収するファイルでより良い調整を
達成するために組み合わせることができます．例えば，`wget -A
"*zelazny*" -R
.ps'は，名前の一部に`zelazny'を持ち，ポストスクリプト*ではない* 
全てのファイルをダウンロードします．

これら2つのオプションは，HTMLファイルのダウンロードで，効果が無いことに
注意してください．Wgetは全てのHTMLをリンク先を知るためにロードする必要が
あります--再帰的な回収は，そうしなければ意味がありません．



File: wget-ja.info, Node: Directory-Based Limits, Next: Relative Links, Prev: Types of Files, Up: Following Links

ディレクトリベースの制限
========================

他のリンクを追う能力にもかかわらず，ファイルがあるディレクトリをもとにし
て回収するファイルの制限を行なうことが役に立つときも良くあります．これに
は多くの理由があります--ホームページは合理的なディレクトリ構造に組織化さ
れているかもしれません．また，いくつかのディレクトリ，例えば`/cgi-bin'や
`/dev'といったディレクトリは，無用な情報を含むかもしれません．

Wgetは，これらの要求を扱うために3つの異なるオプションを提案します．それ
ぞれのオプションでは，短い名前，長い名前，そして`.wgetrc'内の等価コマン
ドをリストアップしています．

`-I LIST'
`--include LIST'
`include_directories = LIST'
     `-I'オプションは，カンマで分けられた回収に含めるディレクトリのリス
     トを受け入れます．他のあらゆるディレクトリは単に無視されます．ディ
     レクトリは絶対パスです．

     そのため，`http://host/people/bozo/'から`/people'ディレクトリのbozo
     の仲間へのリンクと`/cgi-bin'の偽りのスクリプトのみだどってダウンロー
     ドしたい場合，以下のように指定できます．

          wget -I /people,/cgi-bin http://host/people/bozo/

`-X LIST'
`--exclude LIST'
`exclude_directories = LIST'

     `-X'オプションは`-I'の正反対です--これは，ダウンロードから*除外する
     *ディレクトリのリストです．例えば，Wgetで`/cgi-bin'ディレクトリから
     のものをダウンロードしたくない場合，コマンドラインで`-X /cgi-bin'を
     指定してください．

     `-A'/`-R'と同様に，これら2つのオプションは，サブディレクトリのダウ
     ンロードでより良く調整するため，組み合わせることが可能です．例えば，
     `/pub/worthless'以外の`/pub'階層からの全てをロードしたい場合，
     `-I/pub -X/pub/worthless'を指定してください．

`-np'
`--no-parent'
`no_parent = on'
     最も単純な，ディレクトリを制限するためによく利用される便利な方法は，
     開始より*上の*階層を参照するリンクの回収を許可しないことで，すなわ
     ち，親のディレクトリ等への上昇を許可しないことです．

     `--no-parent'オプション(短いものは`-np')はこの状況で役に立ちます．
     それを利用することで，今いる階層から出ないことを保証します．Wgetを
     以下のようにして呼び出したとします．

          wget -r --no-parent http://somehost/~luzer/my-archive/

     これは，`/~his-girls-homepage/'や`/~luzer/all-my-mpegs/'へ参照する
     ものは参照するものをたどらないので安心できます．興味があるアーカイ
     ブのみダウンロードされます．特に，それはより知的な方法でリダイレク
     トを処理するだけなので，`--no-parent'は`-I/~luzer/my-archive'に似て
     います．



File: wget-ja.info, Node: Relative Links, Next: FTP Links, Prev: Directory-Based Limits, Up: Following Links

相対的なリンク
==============

`-L'が開始される時，相対リンクのみ回収されます．相対リンクは，ここではウェ
ブサーバのルートを参照しないものと定義します．例えば以下のリンクは相対的
なものです．

     <a href="foo.gif">
     <a href="foo/bar.gif">
     <a href="../foo/bar.gif">

以下のリンクは相対的ではありません．

     <a href="/foo.gif">
     <a href="/foo/bar.gif">
     <a href="http://www.server.com/foo/bar.gif">

このオプションを使用することで，`-H'を用いない場合でも，再帰的な回収でホ
ストを跨がないことを保証します．単純な状況では，リンクを変換すること無く
"正しく動作する"ダウンロードもできます．

このオプションは，おそらくそんなには役に立たず，将来のリリースでは削除さ
れるかもしれません．



File: wget-ja.info, Node: FTP Links, Prev: Relative Links, Up: Following Links

FTPリンクをだどる
=================

FTPの規則は，必要があって幾分特殊になっています．HTMLドキュメントのFTPリ
ンクは参照の目的を含むことが多く，デフォルトでダウンロードすることが不便
なことがよくあります．

HTMLドキュメントからFTPへのリンクをたどらせるため，`--follow-ftp'オプショ
ンを指定する必要があります．そうすることで，FTPリンクは，`-H'の設定にか
かわらずホストを跨ぎます．FTP リンクがHTTPサーバと同じホストを示すことは
滅多にないので，これは理にかなっています．同じ理由から，`-L'オプションは
そのようなダウンロードで効果がありません．一方，ドメインの受け入れ(`-D')
と接尾子の規則(`-A'と`-R')は通常適用されます．

また，FTPディレクトリへのリンクをたどることは，再帰的回収以上ではないこ
とに注意してください．



File: wget-ja.info, Node: Time-Stamping, Next: Startup File, Prev: Following Links, Up: Top

タイムスタンプ
**************

インターネットからの情報のミラーの側面で最も重要なことの1つは，アーカイ
ブの更新です．

アーカイブを何度も何度もダウンロードすると，わずかに変更されたファイルの
置換だけでは勿体なく，それは，帯域幅とお金の無駄使いの両方を意味し，更新
する時間も無駄になります．これは，全てのミラーツールが逐次的な更新のオプ
ションを提案する理由です．

そのような更新メカニズムは，リモートサーバが"新しい"ファイルの検索でスキャ
ンされることを意味します．これらの新しいファイルのみ古いものに置換されま
す．

以下の2つの条件のどちらか1つが当てはまる場合，ファイルは新しいものと考え
られます．

  1. その名前のファイルが，ローカルにまだ存在しない．

  2. その名前のファイルが存在するが，リモートファイルがローカルファイル
     より後で編集されている．

これを実装するため，プログラムは，ローカルとリモートの両方のファイルが最
後に更新された時間に気付いている必要があります．そのような情報を，我々は
ファイルの"タイムスタンプ"と呼びます．

GNU Wgetのタイムスタンプは，`--timestamping' (`-N')オプションや，
`.wgetrc'での`timestamping = on'の命令を通じて開始されます．このオプショ
ンでそれぞれのファイルをダウンロードするため，Wgetは存在する同じ名前のロー
カルファイルを調査します．それが存在しリモートファイルが古い場合，Wgetは
それをダウンロードしません．

ローカルファイルが存在しない場合やファイルサイズが一致しない場合，Wget 
はタイムスタンプを気にせずに，リモートファイルをダウンロードします．

* Menu:

* Time-Stamping Usage::
* HTTP Time-Stamping Internals::
* FTP Time-Stamping Internals::



File: wget-ja.info, Node: Time-Stamping Usage, Next: HTTP Time-Stamping Internals, Prev: Time-Stamping, Up: Time-Stamping

タイムスタンプの利用
====================

タイムスタンプの利用は単純です．編集日時を保つため，ダウンロードしたいファ
イルに対し以下のようにします．

     wget -S http://www.gnu.ai.mit.edu/

単純に`ls -l'すると，ローカルファイルのタイムスタンプが，サーバから返さ
れるような`Last-Modified'のステータスと同じになります．タイムスタンプ情
報は，見て分かるように，たとえ`-N'がない場合でも(少くともHTTPに対し)ロー
カルに維持されます．

数日後，Wgetにリモートファイルが変化したかどうか調査させ，変化した場合ダ
ウンロードしたい場合もあります．

     wget -N http://www.gnu.ai.mit.edu/

Wgetはサーバに最後に編集した日付を尋ねます．ローカルファイルがサーバと同
じタイムスタンプ，またはより新しい場合，リモートファイルは再取得されませ
ん．しかし，リモートファイルがより最新の場合，Wgetは取得処理を行います．

FTPでも同じように行います．例えば以下のようにします．

     wget "ftp://ftp.ifi.uio.no/pub/emacs/gnus/*"

(URLの周りの引用符は，シェルが`*'を展開することを妨げます．)

ダウンロード後でローカルディレクトリをリスト表示すると，リモートサーバの
ものと一致するタイムスタンプを表示します．`-N'でコマンドを再発行すること
で，Wgetは，前回ダウンロードしてから編集されたファイル*のみ* 再び回収し
ます．

毎週，GNUアーカイブをミラーしたい場合，毎週以下のコマンドを入力するでしょ
う．

     wget --timestamping -r ftp://ftp.gnu.org/pub/gnu/

タイムスタンプは，サーバがタイムスタンプを与えるファイルに対してのみ動作
します．HTTPに対しては，これは`Last-Modified'ヘッダに依存します．FTPに対
しては，これはWgetがパース可能な書式の，日付を用いたディレクトリリストで
得られるものに依存します(*Note FTP Time-Stamping Internals::).



File: wget-ja.info, Node: HTTP Time-Stamping Internals, Next: FTP Time-Stamping Internals, Prev: Time-Stamping Usage, Up: Time-Stamping

HTTPタイムスタンプの内部
========================

HTTPのタイムスタンプは，`Last-Modified'ヘッダの調査により実行されます．
HTTPでファイル`foo.html'を回収したい場合，Wgetは`foo.html'がローカルに存
在しているかどうかを調べます．存在しない場合，`foo.html'は無条件に回収さ
れます．

ローカルにファイルがある場合，Wgetは最初にローカルのタイムスタンプを調べ
(`ls -l'でそれを調べることに似ています)，そして，リモートファイルの情報
を要求するため，`HEAD'要求をリモートサーバに送ります．

`Last-Modified'ヘッダは，ファイルがより最近編集され("新しく"され) たこと
を知るために調査されます．リモートファイルがより新しい場合，ダウンロード
されます．古い場合，Wgetは諦めます． (1) (*Note HTTP Time-Stamping
Internals-Footnotes::)

`-N'とともに`--backup-converted' (`-K')が指定されているとき，サーバファ
イル`X'は，それが現存している場合はローカルファイルの`X.orig'と比較され，
ローカルファイル`X'と比較されません---`--convert-links' (`-k')で変換され
ている場合は常に異なっています．

おそらく，HTTPタイムスタンプは`If-Modified-Since'要求を使用して実装され
るべきです．


File: wget-ja.info  Node: HTTP Time-Stamping Internals-Footnotes, Up: HTTP Time-Stamping Internals

(1) 追加の調査として，Wgetは`Content-Length'ヘッダを見て，そして大
きさを比較します．同じではない場合，リモートファイルはタイムスタンプ告げ
ることにかかわらず，ダウンロードされます．



File: wget-ja.info, Node: FTP Time-Stamping Internals, Prev: HTTP Time-Stamping Internals, Up: Time-Stamping

FTPタイムスタンプの内部
=======================

理論上，FTPタイムスタンプはHTTPと同じように動作しますが，FTPにはヘッダが
ありません--タイムスタンプはディレクトリリストから探し出す必要があります．

FTPダウンロードが，再帰的またはglobを使用している場合，ディレクトリが含
んでいる要求されたファイルに対してファイルリストを取得するために，Wgetは
FTP `LIST'コマンドを使用します．それはリストの解析を試み，それをUnixの
`ls -l'の出力のように扱い，タイムスタンプを抽出します．残りはHTTPに対す
るものと全く同じです．FTPサーバからglobや再帰を使用しないで個別のファイ
ルを回収する時，`-N'を指定しない限りリストアップされたファイルはダウンロー
ドされません(そして，このためファイルにタイムスタンプは付きません)．

全てのディレクトリリストがUnix形式のリストだという仮定は，非常に不自然に
感じるかもしれませんが，経験的にはそうではなく，その理由は，ほとんど(全
て?)のクライアントがそれを理解できるので，多くの非Unix FTPサーバでもUnix
のようなリスト書式を使用しているためです．RFC959定義が，タイムスタンプは
言うまでもなく，ファイルリストを取得する標準的な方法ではないことを覚えて
おいてください．我々は，将来の標準がこのように定義されることを期待するこ
としかできません．

もう1つの非標準の解決方法は，(評判のよい`wu-ftpd'を含め)いくつかのFTPサー
バがサポートする`MDTM'コマンドの使用も含まれていて，それは指定したファイ
ルの正確な時間を返します．Wgetは，将来このコマンドをサポートするかもしれ
ません．



File: wget-ja.info, Node: Startup File, Next: Examples, Prev: Time-Stamping, Up: Top

スタートアップファイル
**********************

コマンドライン引数でWgetのデフォルト設定を変更する方法を知ると，これらの
設定を永久的に行いたいと思うかもしれません．Wgetスタートアップファイル---
`.wgetrc'---を作成するという便利な方法でそうすることが可能です．

さらに，`.wgetrc'は"主な"初期化ファイルとなっていて，強固なパスワードに
対する特別な能力があるので便利です．このためWgetは，`$HOME/.netrc'がある
場合は，その内容を読み込み解釈します．`.netrc'書式はシステムのマニュアル
で見つかります．

Wgetは，コマンドの限定されたセットを認識し，スタートアップ時に`.wgetrc'
を読みます．

* Menu:

* Wgetrc Location::   Location of various wgetrc files.
* Wgetrc Syntax::     Syntax of wgetrc.
* Wgetrc Commands::   List of available commands.
* Sample Wgetrc::     A wgetrc example.



File: wget-ja.info, Node: Wgetrc Location, Next: Wgetrc Syntax, Prev: Startup File, Up: Startup File

Wgetrcの場所
============

初期化時，Wgetはデフォルトで`/usr/local/etc/wgetrc'(または，Wgetがそこに
インストールされていない場合，`/usr/local'ではない接頭辞)にある"global"
なスタートアップファイルを探し，存在する場合はそれからコマンドを読み込み
ます．

それから，ユーザファイルを探します．環境変数`WGETRC'が設定されている場合，
そのファイルをロードしようとします．失敗した場合，それ以上何もしません．

`WGETRC'が設定されていない場合，Wgetは`$HOME/.wgetrc'をロードしようとし
ます．

ユーザ設定がシステム全体のものの後にロードされるということは，ユーザの
wgetrcと衝突した場合，システム全体のwgetrc(デフォルトで
`/usr/local/etc/wgetrc')に*優先*するということを意味します．全体主義の管
理者は不在です！



File: wget-ja.info, Node: Wgetrc Syntax, Next: Wgetrc Commands, Prev: Wgetrc Location, Up: Startup File

Wgetrcの構文
============

wgetrcコマンドの構文は単純です．

     variable = value

"variable"は"コマンド"とも呼ばれます．有効な"value"は異なるコマンドに対
し異なります．

コマンドは大文字小文字とアンダースコアを識別しません．このため，
`DIr__PrefiX'は`dirprefix'と同じです．`#'で始まる行と空白のみ含む行は，
空行として捨てられます．

カンマで分けられたリストを期待するコマンドは，空のコマンドでリストをクリ
アします．そのため，全体的な`wgetrc'で指定された拒絶するリストをリセット
したい場合，以下のようにして行うことができます．

     reject =



File: wget-ja.info, Node: Wgetrc Commands, Next: Sample Wgetrc, Prev: Wgetrc Syntax, Up: Startup File

Wgetrcコマンド
==============

コマンドの完全な組合わせは，以下にリストアップされています．正当な値は，
`='以下にリストアップされています．単純な真偽値は，`on'と`off'，または
`1'と`0'で設定または解除ができます．場合によっては利用可能な変った種類の
真偽値は"lockable Boolean"で，それは，`on'，`off'，`always'，または
`never'に設定可能です．オプションが`always'や`never'に設定されている場合，
Wgetの呼び出しの間中，値は固定されます--コマンドラインオプションは優先さ
れません．

コマンドには，擬似的に任意の値をとるものもあります．ADDRESS値はホスト名
やドットで分けられたIPアドレスが可能です．Nはあらゆる正の整数や，該当す
る場合は無限に対する`inf'が利用可能です．STRING値は，空ではないあらゆる
文字列が可能です．

これらのほとんどのコマンドは，コマンドラインと同じですが(*Note
Invoking::)，時代遅れのものや滅多に使用されないものもあります．

accept/reject = STRING
     `-A'/`-R' (*Note Types of Files::)と同じです．

add_hostdir = on/off
     ホストが前置されたファイル名を利用可/不可にします．`-nH'はそれを不
     可にします．

continue = on/off
     オンに設定した場合，前から存在している部分的に回収されたファイルに
     強制的につなげます．それを設定する前に`-c'を参照して下さい．

background = on/off
     バックグランドへの移行を可/不可にします---`-b'(利用可にする)と同じ
     です．

backup_converted = on/off
     前もって接尾子`.orig'に変換されているファイルの保存を利用可能/不可
     能にします---(可能にする)`-K'と同じです．

base = STRING
     URL入力ファイル内の相対的なURLが，STRINGに相対的なHTMLとして解釈さ
     せることを強制されていると考えます---`-B'と同じです．

bind_address = ADDRESS
     ADDRESSを拘束し，それは`--bind-address'オプションに似ています．

cache = on/off
     オフに設定するとき，サーバキャッシュを不可にします．`-C'オプション
     を参照してください．

convert links = on/off
     相対的でないリンクをローカルに変換します．それは`-k'と同じです．

cookies = on/off
     オフに設定するときクッキーは利用できません．`--cookies'オプションを
     参照してください．

load_cookies = FILE
     FILEからクッキーをロードします．`--load-cookies'オプションを参照し
     てください．

save_cookies = FILE
     FILEにクッキーを保存します．`--save-cookies'オプションを参照してく
     ださい．

cut_dirs = N
     N個のリモートディレクトリコンポーネントを無視します．

debug = on/off
     デバッグモードで，それは`-d'と同じです．

delete_after = on/off
     ダウンロード後削除します---`--delete-after'と同じです．

dir_prefix = STRING
     ディレクトリツリーのトップです---`-P'と同じです．

dirstruct = on/off
     ディレクトリ構造のオン/オフを切替えます--それぞれ`-x'や`-nd'と同じ
     です．

domains = STRING
     `-D' (*Note Spanning Hosts::)と同じです．

dot_bytes = N
     回収中に見ている1ドットが"含む"バイト数(デフォルトで1024)を指定しま
     す．値に`k'や`m'を後置することが可能で，それぞれキロバイトとメガバ
     イトの代替となります．ドットの設定では，必要に応じてドットの回収を
     適応させたり，前もって定義された"styles"を使用することも可能です
     (*Note Download Options::)．

dots_in_line = N
     回収中にそれぞれの行に出力するドットの数(デフォルトで50)を指定しま
     す．

dot_spacing = N
     1クラスタのドットの数(デフォルトで10)を指定します．

exclude_directories = STRING
     ダウンロードから除外したいディレクトリのカンマで分けられたリストを
     指定します---`-X' (*Note Directory-Based Limits::)と同じです．

exclude_domains = STRING
     `--exclude-domains' (*Note Spanning Hosts::)と同じです．

follow_ftp = on/off
     HTMLドキュメントからFTPリンクをたどります--- `--follow-ftp'と同じで
     す．

follow_tags = STRING
     再帰的な回収時に特定のHTMLタグのみたどり，それは`--follow-tags'に似
     ています．

force_html = on/off
     オンに設定された場合，入力ファイル名がHTMLドキュメントと同じと見な
     すことを強制します---`-F'と同じです．

ftp_proxy = STRING
     環境変数で指定されたものの代わりに，STRINGをFTPプロキシとして使用し
     ます．

glob = on/off
     globをオン/オフします---`-g'と同じです．

header = STRING
     `--header'のように，追加ヘッダを定義します．

html_extension = on/off
     `.html'拡張子を，それが無い`text/html'ファイルに追加し，それは`-E'
     に似ています．

http_passwd = STRING
     HTTPパスワードを設定します．

http_proxy = STRING
     環境変数で指定されたものの代わりに，STRINGをHTTPプロキシとして使用
     します．

http_user = STRING
     HTTPユーザをSTRINGに設定します．

ignore_length = on/off
     オンに設定した場合，`Content-Length'ヘッダを無視します．
     `--ignore-length'と同じです．

ignore_tags = STRING
     再帰的な回収時に特定のHTMLタグを無視し，それは`-G' /
     `--ignore-tags'に似ています．

include_directories = STRING
     ダウンロード時にだどりたい，カンマで分けられたディレクトリのリスト
     を指定します---`-I'と同じです．

input = STRING
     `-i'のように，STRINGからURLを読み込みます．

kill_longer = on/off
     content-lengthヘッダで指定されているより長いデータを無効だと考えま
     す(そして所得を試みます)．デフォルトの動作はそこにあるデータと同じ
     だけ保存し，つまり`Content-Length'の値より大きいまたは同じであると
     規定されます．

logfile = STRING
     ログファイルを設定します---`-o'と同じです．

login = STRING
     FTPに対するリモートマシンでのユーザ名です．デフォルトは`anonymous'
     です．

mirror = on/off
     ミラーリングをオン/オフします．`-m'と同じです．

netrc = on/off
     netrcの読み込みをオン/オフします．

noclobber = on/off
     `-nc'と同じです．

no_parent = on/off
     ディレクトリ階層外部への回収を禁止し，それは`--no-parent' (*Note
     Directory-Based Limits::)に似ています．

no_proxy = STRING
     環境変数で指定したものの代わりに，プロキシの負荷を避けるため，
     STRINGを，カンマで分けられたドメインのリストとして使用します．

output_document = STRING
     出力ファイル名を設定します---`-O'と同じです．

page_requisites = on/off
     単一のHTMLページを正しく表示するのに必要な補助的なドキュメントをす
     べてダウンロードします---`-p'と同じです．

passive_ftp = on/off/always/never
     パッシブFTPに設定します---`--passive-ftp'と同じです．いくつか
     のスクリプトと`.pm' (Perlモジュール)ファイルは，`wget
     --passive-ftp'を使用しているファイルをダウンロードします．ファイアウォー
     ルがこれを許可しない場合，コマンドラインを優先するため`passive_ftp
     = never'を指定できます．

passwd = STRING
     FTPパスワードをPASSWORDに設定します．設定していない場合パスワードの
     デフォルトは`username@hostname.domainname'です．


progress = STRING
     進行状況の表紙の形式を設定します．正当な形式は，"ドット"と"バー"で
     す．

proxy_user = STRING
     `--proxy-user'のように，プロキシ認証のユーザ名をSTRINGに設定します．

proxy_passwd = STRING
     `--proxy-passwd'のように，プロキシ認証のパスワードをSTRINGに設定し
     ます．

referer = STRING
     HTTP `Referer:'ヘッダを`--referer'のように設定します．(それは，間違っ
     た"referrer"の綴りを知っていた人が，HTTPスペックを書いた人々だとい
     うことに注意してください．)

quiet = on/off
     静かなモードです---`-q'と同じです．

quota = QUOTA
     ダウンロードのクォータを指定し，それは全体的な`wgetrc'に置くと便利
     です．ダウンロードクォータが指定された場合，Wgetは，ダウンロードの
     合計がクォータより大きくなった後で回収を停止します．クォータはバイ
     ト(デフォルト)，キロバイト(`k'の追加)，またはメガバイト(`m'の追加)
     で指定できます．このため，`quota = 5m'はクォータを5メガバイトに設定
     します．ユーザのスタートアップファイルがシステム設定に優先すること
     に注意してください．

reclevel = N
     再帰のレベルです---`-l'と同じです．

recursive = on/off
     再帰をオン/オフします--それは`-r'と同じです．

relative_only = on/off
     相対リンクのみをたどります---`-L' (*Note Relative Links::)と同じで
     す．

remove_listing = on/off
     オンに設定したとき，WgetがダウンロードしたFTPのリストを削除します．
     オフに設定することは，`-nr'と同じです．

retr_symlinks = on/off
     オンに設定したとき，シンボリックリンクをプレーンファイルであるかの
     ように回収します．`--retr-symlinks'と同じです．

robots = on/off
     `/robots.txt'ファイル(*Note Robots::)を使用します(または使用しませ
     ん)デフォルト(`on')を変更する前に，自分が行っていることが分かってい
     るか確かめてください．

server_response = on/off
     HTTPとFTPサーバのレスポンスの出力を行うかどうか選択します--- `-S'と
     同じです．

span_hosts = on/off
     `-H'と同じです．

timeout = N
     タイムアウトの値を設定します---`-T'と同じです．

timestamping = on/off
     タイムスタンプのオン/オフを切替えます．`-N' (*Note Time-Stamping::) 
     と同じです．

tries = N
     URL毎の再挑戦回数を設定します---`-t'と同じです．

use_proxy = on/off
     プロキシサポートのオン/オフを切替えます．`-Y'と同じです．

verbose = on/off
     冗長出力のオン/オフを切替えます---`-v'/`-nv'と同じです．

wait = N
     回収の間でN秒待ちます---`-w'と同じです．

waitretry = N
     回収の失敗でのリトライのみで，N秒まで待ちます---`--waitretry' と同
     じです．これはデフォルトで，グローバルな`wgetrc'で開始されることに
     注意してください．

randomwait = on/off
     要求間のランダムな待ち時間をオンまたはオフにします．`--random-wait' 
     と同じです．



